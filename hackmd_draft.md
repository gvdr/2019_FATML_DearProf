“Dear Prof, are they going to fire me if I act ethically?” Disappointment, revelation and commitment in an ethics course for Data scientists [the second clause is not really reflected in the abstract]
ABSTRACT 150 words:
Along with the rise of data scientists in industry positions, there is increased interest in the field of data ethics. However, many industry-oriented students and industry workers worry about the practicalities of applying ethical frameworks in their jobs. While the number of programs offering a curriculum in data science has been increasing since 2015, many ethics courses are still taught in (non-CS, non-DS) departments and are not essential to DS/CS curricula. 
In this case study, data science and ethics pedagogy are linked together. Housed in a Master of Applied Data Science at the University of Canterbury (NZ), The Trustworthy Data Scientist is a graduate level course attracting students from wide swaths of educational and cultural backgrounds. The goal is to stimulate aspiring data scientists in recognizing and responding to ethical challenges. This paper discusses mechanisms for creating a dialogue between industry and academia to link data science and ethical action.










"Dear Prof, are they going to fire me if I worry about ethics?" Disappointment, request, and commitment in an ethics course for Data scientists
===

ABSTRACT 150 words:

Along with the rise of data scientists in industry positions, there is an increased interest in expertise in the field of data ethics (or tech ethics). However, many industry-oriented students and current industry workers are concerned about the degree to which they are able to apply ethical reflection and ethical practices in their daily data work. While the number of programs offering a curriculum in data science has been rapidly increasing since 2015, many ethics courses are still taught in (non-CS, non-DS) departments and are not well integrated into the DS/CS curricula: they are either offered as a non-essential elective or as workshops. Moreover, many of the ethics courses offered in quantitive/programming oriented curricula have adopted a pedagogic approach developed in the context of philosophy based curricula. We argue that for these reasons many ethics courses fall short in informing, stimulating, and supporting a cultural change toward ethical data science.
In this paper we show how we link data science and ethics pedagogy in one course, treating it as a case study in practice. The course, offered in the Master of Applied Data Science at the University of Canterbury (New Zealand), is targeted to graduate students with a wide educational, cultural, and motivational diversity. With the hope that both industry workers and the university form a community of data science practice, we named the course _The Trustworthy Data Scientist_. Ultimately, our pedagogical goal is to stimulate and support the commitment of aspiring data scientists to recognize and respond to the ethical requests of a disappointed community, and earn the trust of both other technologists and all those affected by their technology. Because of this, the course both reflects and informs a continuous dialogue with industry- and academia-based community-generated efforts to link data science and ethical action.

===


Possible title: "Dear Prof, are they going to fire me if I worry about ethics?"

OUTLINE FOR COLLABORATIVE REFERENCE
1. Course description
2. CPEDS description (formation of working groups)
3. CHART comparing topics in each "industry concerns"
4. Professor and TA experiences in the trustwothy data scientist
5. community manager experiences in CPEDS (llian and mo)
6. How do we link the two?
7. Creating an industry prepared ethical data scientist
8. Challenges in dialogue building between industry and academic
9. Informing pedagogical structures in ethical data science
10. eye-catching conclusion Creating a global community begins in the classroom (or at least one of the beginnings is in the classroom)

The number of programs offering a curriculum in data science has been rapidly increasing since 2015.
Our ethical and social progress has not kept the pace of the technical progress we have observed.
At the same time, the current practice of data science (Machine Learning, AI) in industry, in academia, and in the public sector is morally deficient.
We routinely fail to honor the trust relationship between practitioner and impacted communities necessary to handle personal and group sensitive data, to operate for the social benefit, and to perform research.
Hence, many in the universities recognize the need to integrate ethics and critical studies in AI / ML / Data Science programs, and a number of such courses start to be offered.
Some of these courses offer a "classic" introduction to ethics: with this we identify courses favoring an historical itinerary in ethical thinking and presenting mostly, or exclusively, white European philosophers.
We question the efficacy of such "classic" courses, based on the lag between [ethical knowledge and ethical action](https://www.tandfonline.com/doi/abs/10.1080/09515089.2019.1587912). 
Here, we describe a radically alternative approach we have taken in developing one such course, "The Trustworthy Data Scientist" (offered in the Master of Applied Data Science at the University of Canterbury, Christchurch, New Zealand).
In particular, we will describe how different pedagogic goals determined the course structure, helped selecting the content offered, and drove class interactions.
In The Trustworthy Data Scientist, our pedagogical goal was to stimulate and support the **commitment** of becoming-data scientists to recognize and respond to the ethical **requests** of a **disappointed** community. Mirroring that goal, and building partly on Simon Critchley's [work](https://www.versobooks.com/books/1135-infinitely-demanding), we structured the course around disappointments, requests, and commitment.




 The course was wrapped around three blocks and component of ethical thinking according to Simon Critchley: Disappointment, Demand, Commitment (approval of the demand in Critchley).

Disappointment, and more precisely in political disappointment "the sense of something lacking or failing arises from the realization that we inhabit a violently unjust world" (Critchley (2007)). In the four weeks, working on material by Safiya Noble, Virginia Eubanks, Anima Anandkumar, Joy Buolamwini, Timnit Gebru, Wendy H. K. Chun, and others we try to identify and describe different examples of unjustice related to unfair algorithmic decision making, information mishandling, privacy violations, ...

Disappointment is given by an ethical demand that does not meet a satisfactory answer. [This part needs to be developed further] "ethical experience begins with the experience of a demand to which I give my approval"

"My basic claim is that ethical experience begins with the approval of a demand, a demand that demands approval. Ethical experience is virtuously circular" (Critchley (2007))

"How does a self bind itself to whatever it determines as its good?" (Critchley (2007))

Disappointment may be met by nihilism, the renounce of trying to better the world: a sentiment that can be expressed in a passive or in an active, burn-it-all-down, fashion: "either passive withdrawal or violent destruction" (Critchley (2007)). In the latter part of the course we instead look at different ways in which a Data Scientist can commit herself to answer the pressing ethical requests that a disappointed society. However, staying clear from the temptation of a "good-enough ethics", a box-ticking approach to ethics that risks to not have enough grip on reality to stimulate a cultural challenge, we once again looked at Simon Critchley and adopted the notion of an "infinitely demanding" ethics ("a conception of ethical experience based on the exorbitant demand of infinite responsibility"(Critchley (2007)) . An ethical framework in which improvement and commitment is never ending, and always possible.

In particular, we looked at the role of Oaths, Codes, Guidelines to both build a principled community of practice around an ethical conception of Data Science and to symbolically express ones own commitment. With the support and the intervention of Te Mana Raraunga (the Māori Data Sovereignty Network) Tahu Kukutai we discussed the role of Indigenous data sovereignty and the role of interacting with the involved community because ethical decisions can only be made in a situated framework.

In exploring the requests and the disappointment, we developed dialogically the need for tools that allowed to go beyond the surface of the stories and to embody our thinking in practice. In this sense, the introduction of notion as Bourdieu's Agent-Networks, or Luciano Floridi's Level of Abstractions and Ontic Trusts where not done within a banking pedagogy framework (Freire) but where thinking tools. Similarly, we needed tools to dialogue about ethics in a group in a fruitful and respectful manner (that we borrowed from Walter Sinnott-Armstrong), to allow for an active role of algorithms and data science products (and we referred to Object Oriented Ontology and Object Oriented Feminism), and so on. The adoption of philosophical concepts as tools allowed for a large flexibility. We were not interested in a philologically correct reading of those notions, but in the satisfaction of a practical, situated need. Learning to map and reflect on an Agent-Network was on par with learning how proxy variable can introduce unfairness in statistical model or how we can use a programming language to probe a dataset.


The students concerns, however brutally, do identify some of the weak points in the course development, which can be referred to some of the weak point in our (the teaching team) theoretical framework weaknesses.

For some of the students it was hard to understand what the assessment units (delivered in the same format of the labs) were requiring. "But how do we get the max grades?" was not a question I was keen in receiving, but it is an all too reasonable question in an education system where grades predicate the career of a student. All assessment were asking the student to elaborate originally on a problem, to show that they could go beyond what directly taught in class. But how do I grade that? How can I give a guideline about students going beyond my guidelines? More in general, if the focus is not on the coding, but on the ethical reflection, how do we grade "ethical reflection"? Do we categorise answers as "right" or "wrong"? And doesn't that contradict our pedagogically founding theme of *not* imposing one moral system on the class? The expedient of assessing not the answer, but the soundness of the argumentation in support of an answer was only partially satisfactory. After all, this was a course in Ethics and not a course in Critical Reasoning.

Or, in other words, if we renounce to a banking pedagogy (Freire) and we base our pedagogy on dialogue, how do we assess dialogue? Conversely, if we want to allow, stimulate, and support the elaboration of an ethical conscience (conscientização, in Freire) how can we make that in parallel with an easily assessable banking pedagogy?

Similarly, the concern about concise but clear and selfsufficient study material points toward a real lack. The course was heavily relying on external material (videos, podcasts, chapters from books, academic and news articles) that in its abundance was overwhelming for students that did not have any previous exposition with similar courses. The expedient of writing lecture notes on the go, based on the class discussions and the results of the lab was only partially sufficient. Elaborating a corpus of selfcontained lecture notes is a heavy task and I lacked the time to do it for every lecture. The tentative of relying on collaborative notetaking (i.e., throught the co-creation of a class wiki) did not work out completely, because of a small class size (18 students was probably not enough to reach critical mass) and because of a poor technological solution (the wiki creation in the class management system offered by the University is cumbersome and counter-intuitive).

Finally, the strong variance in the students programming background made the delivery of the laboratories challenging. Calibrating the labs to that they could challenge everybody, but not overwhelm somebody, was difficult. The choice of using a collaborative programming web interface (Stencila) alleviated some of the issues (i.e., allowing students to start working without installing anything) but brought other glitches (the technology was still in beta development). Pair programming helped to a certain extent, but not fully (autonomous work was still needed).


While many professors expect to continue to be part of the Academy. Many CS students have a necessarily industry aware interest in how ethics are operationalized in their data work.  

The gradient of power must be understood pedagogical relationship. (power dynamics, and the different position, between learner and teacher in the class.) The teacher is often in a liminal space between institution and student. However, when a student leaves institution, they step into a liminal space between industry and community, if they start organizing around ethics. (co-located interests -- maybe expand on that?)

(This could be within the conclusion).part of the teacher's role is to help them to imagine stepping into world where ethics and data science can coincide outside the classroom




link data science and ethics pedagogies in one course as a case study in practice, as well as show how this course both reflects and informs a continuous dialogue with industry-based community-generated efforts to link data science and ethical action.
[the following could be put in a chart to show mirrored concerns from industry-bound students and industry-placed data practioners]
-> Diversity in the course (industry need/concern for diversity of DS, as well as data diversity, Algo bias)
-> Dialogical nature of it (community-based conversations occuring in industry -- Tech Workers Coaltion, Global Data Ethics Project, Data Practices Manifesto)
-> Hands-on-data exercises
[we could use the "topic areas" proposed in the D4GX NYC that created the initial working groups for GDEP. If we do this, then Lilian shoudl be included bc she was doing the community-based wranging at that time.]

(This could be within the conclusion).part of the teacher's role is to help them to imagine stepping into world where ethics and data science can coincide outside the classroom


Something about the fact that the push for the both more applied exercises / projects and for industry discussion comes from the students themselves.


